{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5377440,"sourceType":"datasetVersion","datasetId":3119215}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/renesta/tiny-yolo?scriptVersionId=209753402\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import kagglehub\nimport os\nimport pandas as pd\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport torch.nn as nn\nfrom torchvision import transforms\n\n# Download latest version\npath = kagglehub.dataset_download(\"sbaghbidi/human-faces-object-detection\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:31:32.807557Z","iopub.execute_input":"2024-11-24T01:31:32.807964Z","iopub.status.idle":"2024-11-24T01:31:37.500028Z","shell.execute_reply.started":"2024-11-24T01:31:32.807928Z","shell.execute_reply":"2024-11-24T01:31:37.499204Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5], std=[0.5])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:31:37.501479Z","iopub.execute_input":"2024-11-24T01:31:37.501875Z","iopub.status.idle":"2024-11-24T01:31:37.506201Z","shell.execute_reply.started":"2024-11-24T01:31:37.501847Z","shell.execute_reply":"2024-11-24T01:31:37.505353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Dataset25(Dataset):\n\n  def __init__(self, path, grid_size = 62, YOLO_shape = (1000, 1000), transform = None):\n\n    self.__path = path\n    self.__transform = transform\n    self.__YOLO_shape = YOLO_shape\n    self.__length = 0\n    self.__targets = []\n    self.__images = []\n    self.__grid_size = grid_size\n    csv_path = path + '/faces.csv'\n    df = pd.read_csv(csv_path)\n    df['box_width'] = df['x1'] - df['x0']\n    df['box_height'] = df['y1'] - df['y0']\n\n    for actual_path in self.__get_image_os(path + '/images'):\n\n\n      try:\n\n          row = df[df['image_name'] == actual_path.split('/')[-1]]\n          if row.empty:\n              print(f\"Warning: Image {actual_path} not found in DataFrame.\")\n              continue\n\n          ratio = row['box_width'].iloc[0] * row['box_height'].iloc[0] / (row['width'].iloc[0] * row['height'].iloc[0])\n\n          if ratio >= 0.0 and ratio < 0.25:\n\n              target = np.zeros((self.__grid_size * self.__grid_size, 5), dtype=np.float32)\n              img = Image.open(actual_path)\n\n              x_center = row['x0'].iloc[0] / img.width *  YOLO_shape[0]\n              y_center = row['y0'].iloc[0] / img.height * YOLO_shape[1]\n\n\n              width = row['box_width'].iloc[0] * YOLO_shape[0] / img.width\n              height = row['box_height'].iloc[0] * YOLO_shape[1] / img.height\n\n              grid_x = (self.__grid_size / YOLO_shape[0] * x_center)\n              grid_y = (self.__grid_size / YOLO_shape[1] * y_center)\n\n              target[int(grid_y) * self.__grid_size + int(grid_x)] = [1.0, grid_x - int(grid_x), grid_y - int(grid_y), width, height]\n\n              self.__targets.append(target)\n              self.__images.append(actual_path)\n              self.__length += 1\n\n      except FileNotFoundError:\n          print(f\"Error: Image file not found: {actual_path}\")\n      except Exception as e:\n          print(f\"An error occurred: {e}\")\n\n    print(\"Images and targets created successfully.\")\n\n\n  def get_image_path(self, index):\n\n    return self.__images[index]\n\n  def __get_image_os(self, folder_path):\n\n    for filename in os.listdir(folder_path):\n        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n            yield os.path.join(folder_path, filename)\n    return None\n\n  def __len__(self):\n\n    return self.__length\n\n  def __getitem__(self, index):\n\n      img = Image.open(self.__images[index])\n      img = img.resize(self.__YOLO_shape)\n      img = img.convert('L')\n\n      target = torch.from_numpy(self.__targets[index]).float()\n\n      if self.__transform:\n\n        img = self.__transform(img)\n\n      return img, target\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:31:37.507554Z","iopub.execute_input":"2024-11-24T01:31:37.507887Z","iopub.status.idle":"2024-11-24T01:31:37.521799Z","shell.execute_reply.started":"2024-11-24T01:31:37.507861Z","shell.execute_reply":"2024-11-24T01:31:37.521042Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dt = Dataset25(path, transform= transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:31:37.522744Z","iopub.execute_input":"2024-11-24T01:31:37.522988Z","iopub.status.idle":"2024-11-24T01:31:56.353593Z","shell.execute_reply.started":"2024-11-24T01:31:37.522964Z","shell.execute_reply":"2024-11-24T01:31:56.352779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data, validation_data = random_split(dt, [0.8, 0.2])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:31:56.356603Z","iopub.execute_input":"2024-11-24T01:31:56.356857Z","iopub.status.idle":"2024-11-24T01:31:56.379366Z","shell.execute_reply.started":"2024-11-24T01:31:56.356834Z","shell.execute_reply":"2024-11-24T01:31:56.37879Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = DataLoader(train_data, batch_size = 4, shuffle = True)\nvalidation_loader = DataLoader(validation_data, batch_size = 4, shuffle = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:31:56.380162Z","iopub.execute_input":"2024-11-24T01:31:56.380417Z","iopub.status.idle":"2024-11-24T01:31:56.384612Z","shell.execute_reply.started":"2024-11-24T01:31:56.38038Z","shell.execute_reply":"2024-11-24T01:31:56.383716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class EarlyStopping:\n    \n    def __init__(self, patience=10, verbose=False):\n        self.patience = patience\n        self.verbose = verbose\n        self.best_loss = float('inf')\n        self.counter = 0\n        self.early_stop = False\n\n    def __call__(self, val_loss):\n        if val_loss < self.best_loss:\n            self.best_loss = val_loss\n            self.counter = 0\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True\n                if self.verbose:\n                    print(\"Early stopping triggered.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:31:56.385607Z","iopub.execute_input":"2024-11-24T01:31:56.385855Z","iopub.status.idle":"2024-11-24T01:31:56.395337Z","shell.execute_reply.started":"2024-11-24T01:31:56.385831Z","shell.execute_reply":"2024-11-24T01:31:56.394446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class YoloLoss(nn.Module):\n    def __init__(self, lambda_l2=0.01, lambda_conf=1.0, lambda_box = 0.0001):\n        super(YoloLoss, self).__init__()\n        self.lambda_l2 = lambda_l2\n        self.lambda_conf = lambda_conf\n        self.lambda_box = lambda_box\n        self.bce_loss = nn.BCEWithLogitsLoss(reduction='none')\n        \n\n    def forward(self, predictions, targets):\n\n        object_mask = targets[..., 0] == 1\n        no_object_mask = targets[..., 0] == 0\n\n\n        pred_conf = predictions[..., 0]\n        target_conf = targets[..., 0]\n\n        conf_loss_obj = self.bce_loss(pred_conf[object_mask], target_conf[object_mask]) * 10\n        conf_loss_no_obj = self.bce_loss(pred_conf[no_object_mask], target_conf[no_object_mask])\n\n        '''conf_loss = torch.where(object_mask,\n                              conf_loss * 120.0,\n                              conf_loss * 1.0 / 100.0)\n        conf_loss = conf_loss.mean()\n        '''\n        conf_loss_obj = conf_loss_obj.mean()\n        conf_loss_no_obj = conf_loss_no_obj.mean()\n        \n        pred_boxes = predictions[object_mask]\n        target_boxes = targets[object_mask]\n\n        if pred_boxes.numel() > 0:\n            loss_position = torch.mean((pred_boxes[:, 1:3] - target_boxes[:, 1:3]) ** 2)\n            loss_size = torch.mean((pred_boxes[:, 3:5] - target_boxes[:, 3:5]) ** 2)\n            box_loss = loss_position + loss_size\n        else:\n            box_loss = torch.tensor(0.0, device=predictions.device)\n\n        l2_reg = 0\n        for name, param in model.named_parameters():\n            if 'bias' not in name:\n                l2_reg += torch.norm(param) ** 2\n\n        l2_loss = self.lambda_l2 * l2_reg\n        \n        total_loss = self.lambda_box * box_loss + self.lambda_conf * (conf_loss_obj + conf_loss_no_obj) + l2_loss\n\n        return total_loss, self.lambda_conf * (conf_loss_obj + conf_loss_no_obj), self.lambda_box * box_loss, l2_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:31:56.39649Z","iopub.execute_input":"2024-11-24T01:31:56.397043Z","iopub.status.idle":"2024-11-24T01:31:56.406618Z","shell.execute_reply.started":"2024-11-24T01:31:56.397005Z","shell.execute_reply":"2024-11-24T01:31:56.405664Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class YoloModel(nn.Module):\n    def __init__(self):\n        super(YoloModel, self).__init__()\n\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=1, padding=1)\n        self.bn1 = nn.BatchNorm2d(4)\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.conv2 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=1, padding=1)\n        self.bn2 = nn.BatchNorm2d(8)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.conv3 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n        self.bn3 = nn.BatchNorm2d(16)\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.conv4 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n        self.bn4 = nn.BatchNorm2d(32)\n        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n    \n        self.final_conv = nn.Conv2d(in_channels=32, out_channels=5, kernel_size=1)\n\n\n    def forward(self, x):\n        x = self.pool1(nn.ReLU()(self.bn1(self.conv1(x))))\n        x = self.pool2(nn.ReLU()(self.bn2(self.conv2(x))))\n        x = self.pool3(nn.ReLU()(self.bn3(self.conv3(x))))\n        x = self.pool4(nn.ReLU()(self.bn4(self.conv4(x))))\n        x = self.final_conv(x)\n\n        batch_size = x.size(0)\n        x = x.permute(0, 2, 3, 1).contiguous()\n        x = x.view(batch_size, -1, 5)\n    \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:31:56.407498Z","iopub.execute_input":"2024-11-24T01:31:56.407766Z","iopub.status.idle":"2024-11-24T01:31:56.420153Z","shell.execute_reply.started":"2024-11-24T01:31:56.407743Z","shell.execute_reply":"2024-11-24T01:31:56.419212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef train_epoch(model, dataloader, criterion, optimizer, device):\n    model.train()\n    total_loss = 0\n    total_conf_loss = 0\n    total_box_loss = 0\n    total_l2_loss = 0\n\n    for batch_idx, (inputs, targets) in enumerate(dataloader):\n\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(inputs)\n\n        loss, conf_loss, box_loss, l2_loss = criterion(outputs, targets)\n\n        loss.backward()\n\n        optimizer.step()\n\n        total_loss += loss.item()\n        total_conf_loss += conf_loss.item()\n        total_box_loss += box_loss.item()\n        total_l2_loss += l2_loss.item()\n\n        if batch_idx % 12 == 0:\n            print(f'Batch {batch_idx}, Total Loss: {loss.item():.4f}, '\n                  f'Confidence Loss: {conf_loss.item():.4f}, '\n                  f'Box Loss: {box_loss.item():.4f}, '\n                  f'L2 Loss: {l2_loss.item():.4f}')\n\n\n        if device == 'cuda':\n            torch.cuda.empty_cache()\n\n    return total_loss / len(dataloader)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:31:56.421079Z","iopub.execute_input":"2024-11-24T01:31:56.421351Z","iopub.status.idle":"2024-11-24T01:31:56.431327Z","shell.execute_reply.started":"2024-11-24T01:31:56.421298Z","shell.execute_reply":"2024-11-24T01:31:56.430679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def validate_epoch(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0\n    total_probability_diff = []\n    total_probability_diff1 = []\n\n    with torch.no_grad():\n        for batch_idx, (inputs, targets) in enumerate(dataloader):\n            inputs = inputs.to(device)\n            targets = targets.to(device)\n\n            outputs = model(inputs)\n\n            loss, conf_loss, box_loss, l2_loss = criterion(outputs, targets)\n            total_loss += loss.item()\n\n            object_mask = targets[..., 0] > 0  \n            object_mask1 = targets[..., 0] == 0\n            \n            pred_probabilities = torch.sigmoid(outputs[..., 0])\n\n            \n            if object_mask.any():  \n                \n                predicted_probs_for_objects = pred_probabilities[object_mask]\n                predicted_probs_for_objects1 = pred_probabilities[object_mask1]\n                \n                target_probs_for_objects = targets[..., 0][object_mask]\n                target_probs_for_objects1 = targets[..., 0][object_mask1]\n                \n                probability_diff = predicted_probs_for_objects - target_probs_for_objects\n                probability_diff1 = predicted_probs_for_objects1 - target_probs_for_objects1\n                total_probability_diff.extend(probability_diff.cpu().numpy())\n                total_probability_diff1.extend(probability_diff1.cpu().numpy())\n\n    \n    avg_loss = total_loss / len(dataloader)\n    avg_probability_diff = np.mean(np.abs(total_probability_diff)) if total_probability_diff else 0\n    avg_probability_diff1 = np.mean(np.abs(total_probability_diff1)) if total_probability_diff1 else 0\n\n    return avg_loss, avg_probability_diff, avg_probability_diff1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:31:56.432253Z","iopub.execute_input":"2024-11-24T01:31:56.43304Z","iopub.status.idle":"2024-11-24T01:31:56.442676Z","shell.execute_reply.started":"2024-11-24T01:31:56.433015Z","shell.execute_reply":"2024-11-24T01:31:56.441976Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = YoloModel()\ncriterion = YoloLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1,min_lr=10**(-12))\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\n\n# Основной цикл обучения\nearly_stopping = EarlyStopping(patience=5, verbose=True)\nnum_epochs = 50\nfor epoch in range(num_epochs):\n    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n\n    for name, param in model.named_parameters():\n        if 'bias' in name:\n            param.grad = -param.grad\n    \n    scheduler.step(train_loss)\n\n    val_loss, avg_prob, avg_prob_neg = validate_epoch(model, validation_loader, criterion, device)\n    \n    current_lr = scheduler.get_last_lr()[0]\n    print(f'Epoch {epoch+1}/{num_epochs}, Average Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Probability: {avg_prob:.4f}, Negative Probability: {avg_prob_neg:.4f}, Learning Rate: {current_lr}')\n\n\n    early_stopping(val_loss)\n    if early_stopping.early_stop and current_lr <= 10**(-10): \n        print(\"Training stopped.\")\n        break\n    ","metadata":{"trusted":true,"_kg_hide-output":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef save_checkpoint(model, optimizer, scheduler, epoch, loss, filename):\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'scheduler_state_dict': scheduler.state_dict(),\n        'loss': loss,\n    }, filename)\n\n\nsave_checkpoint(model, optimizer, scheduler, epoch, train_loss, 'checkpoint.pth')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T05:28:51.739617Z","iopub.execute_input":"2024-11-24T05:28:51.739947Z","iopub.status.idle":"2024-11-24T05:29:02.375869Z","shell.execute_reply.started":"2024-11-24T05:28:51.739914Z","shell.execute_reply":"2024-11-24T05:29:02.375184Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_model(checkpoint_path, model_class, optimizer_class=None, device=None):\n    checkpoint = torch.load(checkpoint_path)\n    \n    model = YoloModel()\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model.to(device)\n    model.eval()\n\n    if optimizer_class:\n        optimizer = optimizer_class()\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        return model, optimizer, checkpoint['epoch'], checkpoint['loss']\n    \n    return model, checkpoint['epoch'], checkpoint['loss']\n\n\ndef preprocess_image(img, device):\n    img = img.unsqueeze(0)\n    img = img.to(device)\n    return img\n\ndef get_model_predictions(model, img):\n    with torch.no_grad():\n        outputs = model(img)\n    return outputs\n\ndef process_outputs(outputs):\n    \n    confidence = torch.sigmoid(outputs[0, ..., 0]).reshape(62, 62)\n    positions = outputs[0, ..., 1:3].reshape(62, 62, 2)\n    sizes = outputs[0, ..., 3:5].reshape(62, 62, 2)\n\n    return confidence, positions, sizes\n\ndef draw_bounding_box(img, positions, sizes, confidence, device):\n\n    img = img.cpu()\n    img_np = img.numpy() \n\n    img_np = np.transpose(img_np[0], (1, 2, 0)) * 255.0\n\n\n    for x in range(62):\n        for y in range(62):\n            if confidence[x, y] > 0.99:\n                pos_x, pos_y = positions[x, y]\n\n                pos_x = pos_x.item() * 1000 / 62\n                pos_y = pos_y.item() * 1000 / 62\n\n                print(pos_x, pos_y)\n\n                width, height = sizes[x, y]\n\n                top_left = (int(x * 1000 / 62 - width / 2 + pos_x), int(y * 1000 / 62 - height / 2 + pos_y))\n                bottom_right = (int(x * 1000 / 62 + width / 2 + pos_x), int(y * 1000 / 62 + height / 2 + pos_y))\n\n\n                img_np = cv2.rectangle(img_np, top_left, bottom_right, (255, 0, 0), 2)\n\n    return img_np\n\ndef check_single_image(checkpoint_path, dataset, index, device):\n    model, _, _ = load_model(checkpoint_path, YoloModel, device = device)\n    img, target = dataset[index]\n    img = preprocess_image(img, device)\n    outputs = get_model_predictions(model, img)\n    confidence, positions, sizes = process_outputs(outputs)\n    \n    img_with_boxes = draw_bounding_box(img, positions, sizes, confidence, device)\n    \n    plt.imshow(img_with_boxes)\n    plt.axis('off')\n    plt.show()\n\nimport cv2\ncheck_single_image(\"/content/drive/MyDrive/YOLO/checkpoint.pth\", dt, 1, torch.device('cuda' if torch.cuda.is_available() else 'cpu'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T05:29:02.378154Z","iopub.execute_input":"2024-11-24T05:29:02.37845Z","iopub.status.idle":"2024-11-24T05:29:02.74679Z","shell.execute_reply.started":"2024-11-24T05:29:02.378413Z","shell.execute_reply":"2024-11-24T05:29:02.745549Z"}},"outputs":[],"execution_count":null}]}